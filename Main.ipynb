{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model and move it to GPU\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(device)\n",
    "\n",
    "# Convert model to FP16 (half precision) if CUDA is available\n",
    "if device == \"cuda\":\n",
    "    model.half()\n",
    "\n",
    "# OpenCV to capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Press 'q' to quit the application.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    # Convert frame to PIL image\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Preprocess image and move to GPU\n",
    "    inputs = processor(images=pil_image, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Convert inputs to half precision if using CUDA\n",
    "    if device == \"cuda\":\n",
    "        inputs[\"pixel_values\"] = inputs[\"pixel_values\"].half()\n",
    "\n",
    "    # Perform object detection\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Move outputs back to CPU for processing\n",
    "    target_sizes = torch.tensor([pil_image.size[::-1]], device=device)\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.7)[0]\n",
    "    results = {k: v.cpu() for k, v in results.items()}\n",
    "\n",
    "    # Draw bounding boxes for detected persons\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        if label.item() == 1:  # 1 = \"Person\" in COCO dataset\n",
    "            box = [round(i, 2) for i in box.tolist()]\n",
    "            cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Person: {round(score.item(), 3)}\",\n",
    "                        (int(box[0]), int(box[1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Person Detection', frame)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
